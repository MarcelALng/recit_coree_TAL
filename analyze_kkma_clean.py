#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Analyse Kkma SANS m√©tadonn√©es
Filtre enrichi pour exclure les m√©tadonn√©es des titres
"""

import json
import time
from collections import Counter
from konlpy.tag import Kkma

# Stop words cor√©ens ENRICHIS (avec m√©tadonn√©es)
KOREAN_STOPWORDS_ENRICHED = {
    # Particules
    'Ïù¥', 'Í∞Ä', 'ÏùÑ', 'Î•º', 'ÏùÄ', 'Îäî', 'Ïóê', 'ÏóêÏÑú', 'Ïùò', 'ÏôÄ', 'Í≥º', 'Î°ú', 'ÏúºÎ°ú',
    'ÎèÑ', 'Îßå', 'Î∂ÄÌÑ∞', 'ÍπåÏßÄ', 'ÏóêÍ≤å', 'ÌïúÌÖå', 'Íªò', 'Î≥¥Îã§', 'Ï≤òÎüº', 'Í∞ôÏù¥',
    # Pronoms
    'ÎÇò', 'ÎÑà', 'Ï†Ä', 'Ïö∞Î¶¨', 'Í∑∏', 'Ïù¥', 'Ï†Ä', 'Ïó¨Í∏∞', 'Í±∞Í∏∞', 'Ï†ÄÍ∏∞',
    'Ïù¥Í≤É', 'Í∑∏Í≤É', 'Ï†ÄÍ≤É', 'ÎàÑÍµ¨', 'Î¨¥Ïóá', 'Ïñ¥Îîî', 'Ïñ∏Ï†ú', 'Ïñ¥ÎñªÍ≤å',
    # Verbes auxiliaires
    'ÌïòÎã§', 'ÎêòÎã§', 'ÏûàÎã§', 'ÏóÜÎã§', 'Ïù¥Îã§', 'ÏïÑÎãàÎã§',
    # Adverbes temporels
    'ÏßÄÍ∏à', 'Ïò§Îäò', 'Ïñ¥Ï†ú', 'ÎÇ¥Ïùº', 'Ïó¨Í∏∞', 'Í±∞Í∏∞', 'Ï†ÄÍ∏∞',
    # Conjonctions
    'Í∑∏Î¶¨Í≥†', 'Í∑∏Îü¨ÎÇò', 'ÌïòÏßÄÎßå', 'Îòê', 'ÎòêÌïú', 'Î∞è',
    # Nombres
    'Ïùº', 'Ïù¥', 'ÏÇº', 'ÏÇ¨', 'Ïò§', 'Ïú°', 'Ïπ†', 'Ìåî', 'Íµ¨', 'Ïã≠',
    # Autres mots fonctionnels
    'Îì±', 'Í≤É', 'Ïàò', 'Îïå', 'ÎÖÑ', 'Ïõî', 'Ïùº', 'Ï§ë', 'Í∞Ñ', 'Îßê', 'Ï†ê', 'Î∞î',
    
    # ========== M√âTADONN√âES √Ä FILTRER ==========
    # Titres et sources
    'Îã¥Ìôî', 'Î∞ïÏÇ¨', 'Ïù¥ÏäπÎßå', 'ÎåÄÌÜµÎ†πÏù¥ÏäπÎßå', 'ÎåÄÌÜµÎ†πÏù¥ÏäπÎßåÎ∞ïÏÇ¨',
    'ÎåÄÌÜµÎ†πÏù¥ÏäπÎßåÎ∞ïÏÇ¨Îã¥Ìôî', 'ÎåÄÌÜµÎ†πÏù¥ÏäπÎßåÎ∞ïÏÇ¨Îã¥ÌôîÏßë', 'Í≥µÎ≥¥Ï≤ò', 'Í≥µÎ≥¥Ïã§',
    'Ìé∏', 'Ïßë', 'ÌõàÌôîÎ°ù', 'Ïù¥ÎåÄÌÜµÎ†π', 'Ïù¥ÎåÄÌÜµÎ†πÌõàÌôîÎ°ù',
    # Ann√©es
    '1948', '1949', '1950', '1951', '1952', '1953', '1954', '1955',
    '1956', '1957', '1958', '1959', '1960',
    # Autres m√©tadonn√©es courantes
    'Ï§ëÏïôÎ¨∏ÌôîÌòëÌöå', 'ÊñΩÊîøÊúàÂ†±', 'ÏõîÎ≥¥', 'ÏãúÏ†ï'
}

print("="*80)
print("üìñ ANALYSE KKMA - SANS M√âTADONN√âES")
print("="*80)
print(f"\nüîß Configuration:")
print(f"  ‚Ä¢ Analyseur: Kkma")
print(f"  ‚Ä¢ Filtrage: AVEC stop words enrichis")
print(f"  ‚Ä¢ Stop words totaux: {len(KOREAN_STOPWORDS_ENRICHED)}")
print(f"  ‚Ä¢ Fichier source: president_texts_Lee_Seung_Man.json\n")

# Charger les discours
print("üìÇ Chargement des discours...")
with open("president_texts_Lee_Seung_Man.json", "r", encoding="utf-8") as f:
    speeches = json.load(f)

total_speeches = len(speeches)
print(f"   ‚úì {total_speeches:,} discours charg√©s\n")

# Initialiser Kkma
print("üîß Initialisation de Kkma...")
kkma = Kkma()
print("   ‚úì Analyseur pr√™t\n")

# Analyser tous les discours
print("="*80)
print("üîç ANALYSE EN COURS...")
print("="*80)

start_time = time.time()
all_nouns = []

for idx, speech in enumerate(speeches, 1):
    if idx % 100 == 0:
        elapsed = time.time() - start_time
        print(f"  Progression: {idx}/{total_speeches} discours ({elapsed:.1f}s)")
    
    # Combiner tous les paragraphes
    text = " ".join(speech["paragraphs"])
    
    # Extraire les noms
    nouns = kkma.nouns(text)
    
    # Filtrer les stop words ET m√©tadonn√©es
    nouns_filtered = [
        word for word in nouns 
        if word not in KOREAN_STOPWORDS_ENRICHED 
        and len(word) > 1
        and not word.isdigit()  # Exclure les nombres purs
    ]
    
    all_nouns.extend(nouns_filtered)

total_time = time.time() - start_time

print(f"\n‚úÖ Analyse termin√©e en {total_time:.2f} secondes")
print(f"   Vitesse: {total_speeches/total_time:.1f} discours/seconde\n")

# Calculer les statistiques
word_freq = Counter(all_nouns)
top_50 = word_freq.most_common(50)

print("="*80)
print("üìä STATISTIQUES GLOBALES")
print("="*80)
print(f"  Total de noms extraits    : {len(all_nouns):,}")
print(f"  Noms uniques              : {len(word_freq):,}")
print(f"  Moyenne par discours      : {len(all_nouns)/total_speeches:.1f} noms")
print(f"  Stop words filtr√©s        : {len(KOREAN_STOPWORDS_ENRICHED)}")

print("\n" + "="*80)
print("üèÜ TOP 50 MOTS LES PLUS FR√âQUENTS (SANS M√âTADONN√âES)")
print("="*80)
for rank, (word, count) in enumerate(top_50, 1):
    print(f"  {rank:2d}. {word:20s} : {count:6,d} fois")

# Pr√©parer les r√©sultats
results = {
    "metadata": {
        "president": "Lee Seung Man (Ïù¥ÏäπÎßå)",
        "analyzer": "Kkma",
        "stopwords_filtering": True,
        "metadata_filtering": True,
        "total_speeches": total_speeches,
        "execution_time_seconds": round(total_time, 2),
        "speeches_per_second": round(total_speeches/total_time, 2),
        "analysis_date": "2025-12-09"
    },
    "statistics": {
        "total_nouns_extracted": len(all_nouns),
        "unique_nouns": len(word_freq),
        "average_nouns_per_speech": round(len(all_nouns)/total_speeches, 1),
        "stopwords_count": len(KOREAN_STOPWORDS_ENRICHED)
    },
    "top_50_words": [
        {
            "rank": rank,
            "word": word,
            "frequency": count,
            "percentage": round(100 * count / len(all_nouns), 2)
        }
        for rank, (word, count) in enumerate(top_50, 1)
    ]
}

# Sauvegarder
output_file = "kkma_no_metadata_analysis.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print("\n" + "="*80)
print("üíæ R√âSULTATS SAUVEGARD√âS")
print("="*80)
print(f"  Fichier: {output_file}")

print("\n" + "="*80)
print("‚úÖ ANALYSE KKMA SANS M√âTADONN√âES TERMIN√âE")
print("="*80)
